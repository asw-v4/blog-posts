{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualising the internals of a neural network"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Introduction\n",
    "Welcome to this interactive Jupyter notebook which is a companion to our blog post \"Visualising the Internals of a Neural Network\". In this notebook, we will dive into the intricacies of neural networks and use the PyTorch library in Python to visualize the inner workings of these sophisticated machine learning models.\n",
    "\n",
    "As we proceed, we will demystify concepts such as layers, weights, biases, activation functions, and more, by not just discussing them, but also providing interactive code snippets. By the end of this notebook, we hope to provide you with a hands-on understanding of neural networks and give you insights that are not apparent from the model's final output.\n",
    "\n",
    "Please note, to fully engage with this notebook, it is recommended to have a basic understanding of Python programming, and some familiarity with machine learning concepts and PyTorch would be advantageous. However, we will attempt to make this resource as beginner-friendly as possible."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Setup and Import Libraries\n",
    "Before we start exploring the internals of a neural network, we need to make sure we have all the necessary libraries installed and imported. This notebook primarily relies on PyTorch, a popular open-source machine learning library for Python. If you do not have PyTorch installed already, please uncomment and run the first cell.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To install PyTorch, uncomment and run the below line\n",
    "# !pip install torch torchvision"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apart from PyTorch, we will use other standard Python libraries such as NumPy and Matplotlib for numerical operations and data visualization, respectively. Let's import these:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch Version: 2.0.1+cpu\n",
      "Device: cpu\n"
     ]
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as dsets\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Let's check the version of PyTorch\n",
    "print(f\"PyTorch Version: {torch.__version__}\")\n",
    "\n",
    "# Verify if CUDA is available and if not, use CPU\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Device: {device}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By running the above code, we import the necessary libraries and check the version of PyTorch. We also set the device to CUDA if it's available. CUDA is a parallel computing platform by NVIDIA, and using it can substantially speed up computation time. If CUDA isn't available, we'll use the CPU for computations.\n",
    "\n",
    "Remember, throughout this notebook, we'll assume that the device is set as defined above. If you're running this on your local machine and it doesn't have a GPU (or the GPU isn't set up for CUDA), computations might be slower.\n",
    "\n",
    "In the next section, we will dig deeper into the basics of neural networks. Stay tuned!"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Basics of Neural Networks\n",
    "A neural network is a computational model inspired by the way biological brains process information. These models are used in machine learning and artificial intelligence to solve complex problems that require the machine to 'learn' from data.\n",
    "\n",
    "Neural networks are made up of layers of interconnected nodes or 'neurons'. Each neuron receives input from some neurons in the previous layer, performs a computation, and passes the output to neurons in the next layer. The input layer of the network takes in raw data, each hidden layer performs computations, and the output layer produces the final result.\n",
    "\n",
    "Here are some key concepts:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Neurons**: The fundamental unit of a neural network. A neuron takes inputs, performs a computation on them, and produces an output. Each neuron is associated with a weight and a bias.\n",
    "\n",
    "**Weights and Biases**: Weights control the strength of the connection between two neurons. Biases allow you to shift the activation function curve up or down.\n",
    "\n",
    "**Activation Functions**: These are mathematical equations that determine the output of a neural network. The function is attached to each neuron in the network, and determines whether it should be activated based on the weighted sum of its input.\n",
    "\n",
    "**Layers**: A neural network is typically organized into layers. Layers are made up of multiple neurons. There are three types of layers: input layer, hidden layer(s), and output layer.\n",
    "\n",
    "We'll dig deeper into these concepts in the following sections and visualize them with PyTorch. The goal is to build an intuitive understanding of how neural networks learn from data, how they self-update, and how the different components interact with each other.\n",
    "\n",
    "In the next section, we will begin our exploration by setting up our environment and importing the necessary Python libraries."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Understanding and Visualizing Layers in a Neural Network\n",
    "In a neural network, layers play a critical role in transforming input data into the output. The layers are interconnected through their nodes or neurons, where the transformation of data happens based on the weights and bias."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are three types of layers in a neural network:\n",
    "\n",
    "**Input Layer**: This is the very first layer where each neuron corresponds to one feature of the input data. The input layer simply passes the input it receives to the next layer, often called the first hidden layer.\n",
    "\n",
    "**Hidden Layer(s)**: These are the layers after the input layer and before the output layer. The hidden layers are responsible for learning and representing various levels of abstractions of the input data.\n",
    "\n",
    "**Output Layer**: This is the final layer in a neural network. It provides the output of the model in the format suitable for the problem at hand, such as a single neuron for binary classification problems or multiple neurons for multiclass problems.\n",
    "\n",
    "Let's demonstrate how we can create a neural network and visulaise its layers using PyTorch:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a simple feedforward neural network\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        \n",
    "        # An input layer with 784 neurons (for MNIST data), and a subsequent hidden layer with 128 neurons\n",
    "        self.fc1 = nn.Linear(784, 128)\n",
    "        \n",
    "        # A hidden layer with 128 neurons, and an output layer with 10 neurons (for the 10 output classes of MNIST)\n",
    "        self.fc2 = nn.Linear(128, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self.fc1(x)\n",
    "        x = torch.relu(x)\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "# Create an instance of the network\n",
    "model = Net().to(device)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This will print out a textual representation of our neural network. Each `Linear` function represents a layer in our network. The numbers represent the number of neurons in each layer. For instance, `Linear(in_features=784, out_features=128, bias=True)` represents a layer where 784 inputs are transformed into 128 outputs.\n",
    "\n",
    "As we move forward, we will dive deeper into these layers, revealing the weights and biases that drive their computations, and visually inspect the features these layers learn to capture and the transformations they apply to the input data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Weights and Biases\n",
    "Weights and biases are the learnable parameters of a neural network. They are the sources of the computation power of neural networks, enabling them to solve complex pattern recognition tasks."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Weights**: Weights are parameters learned by the network that determine how much influence a given input will have on a neuron's output. In simple terms, they decide how important a given input feature is for making a correct prediction.\n",
    "\n",
    "**Biases**: Biases, on the other hand, are also learnable parameters that allow each neuron to shift its activation function to the left or right, which can be critical for successful learning.\n",
    "\n",
    "During the training process, the neural network algorithm adjusts the weights and biases to minimize the difference between the actual output and the predicted output. This iterative optimization is usually done via backpropagation and gradient descent.\n",
    "\n",
    "In PyTorch, you can access the weights and biases of a model using the `parameters()` or `state_dict()` functions.\n",
    "\n",
    "Let's access the weights and biases of our previously defined model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the model's state_dict\n",
    "print(\"Model's state_dict:\")\n",
    "for param_tensor in model.state_dict():\n",
    "    print(param_tensor, \"\\t\", model.state_dict()[param_tensor].size())\n",
    "\n",
    "# Print specific weights\n",
    "print(\"\\nWeights of first layer:\")\n",
    "print(model.fc1.weight.data)\n",
    "\n",
    "# Print specific biases\n",
    "print(\"\\nBiases of first layer:\")\n",
    "print(model.fc1.bias.data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `state_dict` function prints the entire state of the model, which includes weights and biases for all layers. The `weight.data` and `bias.data` lines print the weights and biases of the specified layer, respectively.\n",
    "\n",
    "Remember, these weights and biases are randomly initialized and hold no significant value until the network has been trained.\n",
    "\n",
    "In the next section, we will move forward and visualize the activation maps of the model's layers. This will help us understand what these weights and biases have learned to represent after the model is trained."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5b. Data Preparation and Model Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before we proceed with visualizing the internals of our neural network, we need to train our model. For this exercise, we'll use the MNIST dataset, a set of 70,000 small images of digits handwritten by high school students and employees of the US Census Bureau. PyTorch has convenient methods for loading this dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, let's load the data and prepare the dataloaders:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define transformations for normalization and conversion to tensor\n",
    "transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5,), (0.5,))])\n",
    "\n",
    "# Load MNIST dataset\n",
    "train_data = dsets.MNIST(root='./data', train=True, download=True, transform=transform)\n",
    "test_data = dsets.MNIST(root='./data', train=False, download=True, transform=transform)\n",
    "\n",
    "# Create dataloaders\n",
    "batch_size = 100\n",
    "train_loader = torch.utils.data.DataLoader(dataset=train_data, batch_size=batch_size, shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(dataset=test_data, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's train our model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set loss and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Training loop\n",
    "epochs = 25\n",
    "for epoch in range(epochs):\n",
    "    for i, (images, labels) in enumerate(train_loader):  \n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        \n",
    "        # Forward pass to get output\n",
    "        outputs = model(images)\n",
    "        \n",
    "        # Calculate Loss\n",
    "        loss = criterion(outputs, labels)\n",
    "        \n",
    "        # Clearing the accumulated gradients\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # Getting gradients w.r.t. parameters\n",
    "        loss.backward()\n",
    "        \n",
    "        # Updating parameters\n",
    "        optimizer.step()\n",
    "    \n",
    "    print(f'Epoch: {epoch+1}, Loss: {loss.item()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This script will train the model for 25 epochs on the MNIST data. We use cross-entropy as our loss function and the Adam optimizer for backpropagation. You should see the loss decreasing after each epoch, which indicates that our model is learning to classify the digits correctly. A more thorough walkthrough for model training will be made available in a future blog post.\n",
    "\n",
    "In the following sections, we will start diving into the internals of our model, beginning with understanding and visualizing the weights and biases."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Activation Maps\n",
    "Activation maps, also known as feature maps, represent the outputs of the neurons in a layer. These maps can provide us with insights into what features the neural network is learning and recognizing. For instance, in a convolutional neural network, initial layers may activate in response to edges, colors, or textures, while deeper layers may activate in response to more complex patterns or objects."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To demonstrate how we can visualise these activation maps, we'll first need a trained model and some input data. For simplicity, let's train our previously defined model on a few epochs of the MNIST dataset. Then, we'll use one image from the dataset and see how it activates the neurons in the layers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get one batch of test images\n",
    "dataiter = iter(test_loader)\n",
    "images, labels = dataiter.next()\n",
    "\n",
    "# Select an image\n",
    "image = images[0]\n",
    "\n",
    "# Forward pass through the network\n",
    "model.eval() # Set the model to evaluation mode\n",
    "img = image.unsqueeze(0).to(device)\n",
    "output = model(img)\n",
    "\n",
    "# Plot the original image\n",
    "plt.figure(figsize=(10,10))\n",
    "plt.subplot(1,2,1)\n",
    "plt.title(\"Original Image\")\n",
    "plt.imshow(img.cpu().numpy().squeeze(), cmap='gray')\n",
    "\n",
    "# Plot the activation of the first layer\n",
    "plt.subplot(1,2,2)\n",
    "plt.title(\"Activation Map of First Layer\")\n",
    "plt.imshow(model.fc1.weight.data.cpu().numpy(), cmap='gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this example, we plot the original image and the activation map side by side for comparison. The activation map shows how much each neuron in the first layer has been activated by the input image. Bright spots represent higher activation, which means those neurons have recognized patterns in the input image they were designed to detect.\n",
    "\n",
    "This kind of visualization can give us insight into what kind of features each layer is learning, and how the network is interpreting the input data.\n",
    "\n",
    "In the next sections, we will look at how we can monitor and visualize the training process, and how we can visualize high-dimensional feature spaces. Stay tuned!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Monitoring the Training Process\n",
    "Monitoring the training process is crucial for understanding the model's performance over time, diagnosing issues, and improving the model's architecture. You typically monitor loss and accuracy, but other metrics could also be relevant, depending on the problem at hand.\n",
    "\n",
    "Let's modify our training loop from section 5b to store the loss and accuracy at each epoch:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Placeholders for metrics\n",
    "train_loss = []\n",
    "train_accuracy = []\n",
    "\n",
    "# Training loop\n",
    "epochs = 25\n",
    "for epoch in range(epochs):\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for i, (images, labels) in enumerate(train_loader):  \n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        \n",
    "        # Forward pass to get output\n",
    "        outputs = model(images)\n",
    "        \n",
    "        # Calculate Loss\n",
    "        loss = criterion(outputs, labels)\n",
    "        \n",
    "        # Getting predictions from the maximum value\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        \n",
    "        # Total number of labels\n",
    "        total += labels.size(0)\n",
    "        \n",
    "        # Total correct predictions\n",
    "        correct += (predicted == labels).sum()\n",
    "        \n",
    "        # Clearing the accumulated gradients\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # Getting gradients w.r.t. parameters\n",
    "        loss.backward()\n",
    "        \n",
    "        # Updating parameters\n",
    "        optimizer.step()\n",
    "    \n",
    "    train_loss.append(loss.item())\n",
    "    train_accuracy.append(100 * correct / total)\n",
    "    \n",
    "    print(f'Epoch: {epoch+1}, Loss: {loss.item()}, Accuracy: {100 * correct / total}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We added a few lines to calculate accuracy and save both loss and accuracy for each epoch. The accuracy is calculated as the number of correct predictions over the total number of predictions.\n",
    "\n",
    "Now, let's visualize the loss and accuracy over time:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot loss over time\n",
    "plt.figure(figsize=(12,6))\n",
    "plt.subplot(1,2,1)\n",
    "plt.plot(train_loss, label='Training Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Loss over Time')\n",
    "plt.legend()\n",
    "\n",
    "# Plot accuracy over time\n",
    "plt.subplot(1,2,2)\n",
    "plt.plot(train_accuracy, label='Training Accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title('Accuracy over Time')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These graphs should show the loss decreasing and the accuracy increasing over time, indicating that the model is learning from the data.\n",
    "\n",
    "Monitoring the training process is a powerful tool in your machine learning toolkit. It allows you to understand how your model is learning, when it has finished learning or if it is overfitting, and if there is any need for architecture tuning or hyperparameter adjustment. As stated in section 5b, the training, validation, and testing of a model will be covered much more thoroughly in a future blog post."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Visualizing High-Dimensional Feature Spaces\n",
    "Neural networks, especially deep ones, transform input data into a complex, high-dimensional feature space. Visualizing these feature spaces can be challenging due to their high dimensionality, but it can provide valuable insights into what the network is learning."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One common approach is to use dimensionality reduction techniques like t-SNE or PCA to project the high-dimensional features onto a 2D or 3D space that we can easily visualize.\n",
    "\n",
    "Let's demonstrate this with our model's output from the second-to-last layer, right before the final classification. We'll take a batch of images, pass them through the network until the second-to-last layer, and then use t-SNE to visualize the resulting features:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.manifold import TSNE\n",
    "\n",
    "# Get one batch of test images\n",
    "dataiter = iter(test_loader)\n",
    "images, labels = dataiter.next()\n",
    "\n",
    "# Pass the images through the network until the second-to-last layer\n",
    "model.eval() \n",
    "images = images.to(device)\n",
    "output = model.fc1(images.view(images.shape[0], -1)).detach().cpu().numpy()\n",
    "\n",
    "# Use t-SNE to reduce dimensionality for visualization\n",
    "tsne = TSNE(n_components=2, random_state=0)\n",
    "output_tsne = tsne.fit_transform(output)\n",
    "\n",
    "# Plot the result\n",
    "plt.figure(figsize=(10,10))\n",
    "for i in range(10):\n",
    "    indices = labels.numpy() == i\n",
    "    plt.scatter(output_tsne[indices, 0], output_tsne[indices, 1], label=str(i))\n",
    "plt.legend()\n",
    "plt.title('t-SNE of the Second-to-Last Layer')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this plot, each point represents an image, and the color indicates the image's true class. If the network has learned useful features, then images from the same class should appear closer together in this plot.\n",
    "\n",
    "This kind of visualization can help us understand how the network is interpreting the input data, and whether it's learning features that effectively separate the different classes.\n",
    "\n",
    "Remember, though, that these visualizations are only approximations, and high-dimensional spaces can have properties and structures that don't translate well into 2D or 3D."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Understanding the Decision Boundary\n",
    "\n",
    "A decision boundary is a hypersurface that partitions the underlying input space into two or more class regions. For a binary classification problem, the decision boundary separates the space into two regions, one for each class. The decision boundary is where your model is equally likely to classify an input point as one class or the other."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Understanding the decision boundary can provide significant insights into the behavior of your model. In particular, it can show how your model separates different classes and whether it's capturing the relationships in the data correctly.\n",
    "\n",
    "Let's visualize the decision boundary for a simple binary classification problem solved by our neural network. We'll assume for simplicity that our inputs are 2-dimensional, so we can easily plot them along with the decision boundary.\n",
    "\n",
    "For larger dimensional data, you would have to select two dimensions to visualize or reduce dimensions using a method like PCA or t-SNE like we did earlier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Flatten the images\n",
    "images_flat = images.view(images.shape[0], -1).cpu().data.numpy()\n",
    "\n",
    "# Create a grid within the range of our dataset\n",
    "x_min, x_max = images_flat[:, 0].min() - 1, images_flat[:, 0].max() + 1\n",
    "y_min, y_max = images_flat[:, 1].min() - 1, images_flat[:, 1].max() + 1\n",
    "\n",
    "xx, yy = np.meshgrid(np.arange(x_min, x_max, 0.1),\n",
    "                     np.arange(y_min, y_max, 0.1))\n",
    "\n",
    "# Pass the points through the model\n",
    "model.eval() \n",
    "grid_points = torch.tensor(np.c_[xx.ravel(), yy.ravel()], dtype=torch.float).to(device)\n",
    "outputs = model(grid_points)\n",
    "_, preds = torch.max(outputs, 1)\n",
    "\n",
    "# Reshape the predictions to match the grid\n",
    "preds = preds.cpu().data.numpy().reshape(xx.shape)\n",
    "\n",
    "# Plot the decision boundary\n",
    "plt.contourf(xx, yy, preds, alpha=0.4)\n",
    "plt.scatter(images_flat[:, 0], images_flat[:, 1], c=labels, edgecolors='k')\n",
    "plt.title('Decision Boundary')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this script, we first extract a batch of our test data and flatten the images for simplicity. We then create a grid within the range of our dataset. After this, we pass these points through our model and reshape the predictions to match our grid. Finally, we plot the decision boundary along with our data points.\n",
    "\n",
    "This plot can help you understand how your model is making decisions and whether it's correctly capturing the boundaries between classes.\n",
    "\n",
    "Remember, though, that this method of visualizing the decision boundary only works well for low-dimensional data. For higher-dimensional data, the decision boundary can be hard to visualize and interpret."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Conclusions and Next Steps\n",
    "In this notebook, we have explored some techniques for visualizing and understanding the internals of a neural network using PyTorch. We've seen how to visualize the weights and biases, the activation maps, monitor the training process, and even project high-dimensional feature spaces into 2D for visualization."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From these visualizations, we can gain valuable insights into our model's behavior, which can guide us in improving its performance.\n",
    "\n",
    "Here are some key takeaways:\n",
    "\n",
    "**Weights and biases** give us an understanding of how our model transforms inputs, with their visualizations showing us the patterns that neurons have learned.\n",
    "\n",
    "**Activation maps** help us understand what features are activating the neurons in a given layer, and how the network is interpreting the input data.\n",
    "\n",
    "**Monitoring the training process** can help us spot issues like overfitting and underfitting, understand when the model has finished learning, and guide us in tuning the architecture or hyperparameters.\n",
    "\n",
    "**Visualizing high-dimensional feature spaces** provides insights into how the network is distinguishing between different classes, and whether it's learning features that effectively separate the different classes.\n",
    "\n",
    "Remember, these visualizations are just tools to help us better understand and interpret our models, and they're not always perfect or complete. They should be used in combination with good machine learning practices, like proper data preprocessing, model evaluation, and error analysis.\n",
    "\n",
    "In the future, you may want to explore other visualization techniques as well, such as saliency maps, Grad-CAM, or even newer methods that continue to be developed in this active research area.\n",
    "\n",
    "Also, different types of networks (like Convolutional Neural Networks or Recurrent Neural Networks) may have their own unique visualization techniques.\n",
    "\n",
    "Exploring these different methods can give you an even deeper understanding of your models and help you become an even more effective machine learning practitioner."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
